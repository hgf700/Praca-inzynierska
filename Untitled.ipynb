{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f379d6-c675-446e-b649-72165bda0d83",
   "metadata": {},
   "source": [
    "# Early Steps of Work: Creating Test Data in csv & Testing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb3cbfc-5d38-4b7e-a63e-9251738822c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plik grafik.csv został zapisany.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "days = 3\n",
    "employees = 3\n",
    "sample = 10\n",
    "max_tries = 1000\n",
    "\n",
    "def generate_schedule_from_preferences(preferences, firm_requirements, num_days=days, max_tries=max_tries):\n",
    "    num_emps = len(preferences)\n",
    "    schedule = [[0 for _ in range(num_emps)] for _ in range(num_days)]\n",
    "    for e in range(num_emps):\n",
    "        available_days = [d for d in range(num_days) if preferences[e][d] == 1]\n",
    "        if len(available_days) < firm_requirements[e]:\n",
    "            return None\n",
    "        chosen = random.sample(available_days, firm_requirements[e])\n",
    "        for d in chosen:\n",
    "            schedule[d][e] = 1\n",
    "    return schedule\n",
    "\n",
    "def is_schedule_valid(schedule, firm_requirements):\n",
    "    if schedule is None:\n",
    "        return False\n",
    "    num_days = len(schedule)\n",
    "    num_emps = len(schedule[0])\n",
    "    col_sums = [sum(schedule[d][e] for d in range(num_days)) for e in range(num_emps)]\n",
    "    return col_sums == firm_requirements\n",
    "\n",
    "def generate_dataset_csv(filename=\"grafik.csv\", num_samples=sample, num_emps=employees, num_days=days, max_tries=max_tries):\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header = [f\"emp{e}_pref{d}\" for e in range(num_emps) for d in range(num_days)] + \\\n",
    "                 [f\"req_worker{e}\" for e in range(num_emps)] + \\\n",
    "                 [f\"day{d}_emp{e}\" for d in range(num_days) for e in range(num_emps)]\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        samples_generated = 0\n",
    "        attempts = 0\n",
    "        while samples_generated < num_samples and attempts < max_tries * num_samples:\n",
    "            preferences = [[random.randint(0, 1) for _ in range(num_days)] for _ in range(num_emps)]\n",
    "            firm_requirements = [random.randint(1, num_days) for _ in range(num_emps)]\n",
    "            valid = True\n",
    "            for e in range(num_emps):\n",
    "                if sum(preferences[e]) < firm_requirements[e]:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if not valid:\n",
    "                attempts += 1\n",
    "                continue\n",
    "            \n",
    "            schedule = generate_schedule_from_preferences(preferences, firm_requirements, num_days, max_tries)\n",
    "            if schedule is not None and is_schedule_valid(schedule, firm_requirements):\n",
    "                row = []\n",
    "                for e in range(num_emps):\n",
    "                    row.extend(preferences[e])\n",
    "                row.extend(firm_requirements)\n",
    "                for d in range(num_days):\n",
    "                    row.extend(schedule[d])\n",
    "                writer.writerow(row)\n",
    "                samples_generated += 1\n",
    "            attempts += 1\n",
    "        \n",
    "        print(f\"Generated {samples_generated} samples after {attempts} attempts.\")\n",
    "        print(f\"File {filename} has been saved.\")\n",
    "\n",
    "generate_dataset_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd90468-a263-4af5-8e49-4993e2ef23ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER098\\Documents\\GitHub\\Praca-inzynierska\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.7571 - val_loss: 0.7193\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7097 - val_loss: 0.6831\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6755 - val_loss: 0.6536\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6446 - val_loss: 0.6261\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6153 - val_loss: 0.5983\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5901 - val_loss: 0.5691\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5613 - val_loss: 0.5391\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5301 - val_loss: 0.5108\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5016 - val_loss: 0.4876\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4821 - val_loss: 0.4719\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4639 - val_loss: 0.4634\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4607 - val_loss: 0.4603\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4445 - val_loss: 0.4594\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4489 - val_loss: 0.4594\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4442 - val_loss: 0.4590\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4408 - val_loss: 0.4591\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4383 - val_loss: 0.4595\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4376 - val_loss: 0.4593\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4374 - val_loss: 0.4588\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4378 - val_loss: 0.4587\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4368 - val_loss: 0.4590\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4393 - val_loss: 0.4589\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4309 - val_loss: 0.4593\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4377 - val_loss: 0.4596\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4332 - val_loss: 0.4600\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.4288 - val_loss: 0.4600\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4283 - val_loss: 0.4601\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4313 - val_loss: 0.4605\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4295 - val_loss: 0.4606\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4256 - val_loss: 0.4608\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4267 - val_loss: 0.4610\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4208 - val_loss: 0.4618\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4220 - val_loss: 0.4617\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4178 - val_loss: 0.4624\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4269 - val_loss: 0.4624\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4267 - val_loss: 0.4631\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4181 - val_loss: 0.4640\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4141 - val_loss: 0.4645\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4168 - val_loss: 0.4655\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4051 - val_loss: 0.4657\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4238 - val_loss: 0.4658\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4166 - val_loss: 0.4665\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4115 - val_loss: 0.4674\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4130 - val_loss: 0.4681\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4096 - val_loss: 0.4684\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4113 - val_loss: 0.4688\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4073 - val_loss: 0.4696\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4019 - val_loss: 0.4706\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4043 - val_loss: 0.4708\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4032 - val_loss: 0.4714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Przewidywany harmonogram (pierwsze 21 wartości):\n",
      "[0.11253785 0.11099198 0.3190205  0.19442478 0.08421508 0.03429542\n",
      " 0.16180497 0.09020395 0.22402117 0.19677392 0.11054748 0.03732837\n",
      " 0.1985674  0.0824229  0.2527232  0.1456191  0.27466395 0.20553507\n",
      " 0.02638385 0.271368   0.14785327]\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 3. TRENOWANIE SIECI NEURONOWEJ\n",
    "# ====================================================\n",
    "# Poniżej przykład z Keras (TensorFlow).\n",
    "# Musisz mieć zainstalowane biblioteki: tensorflow lub keras.\n",
    "# Jeżeli nie masz – zainstaluj:\n",
    "#   pip install tensorflow\n",
    "# lub\n",
    "#   pip install keras\n",
    "# (zależnie od wersji Pythona i środowiska).\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam,Adadelta ,Adafactor ,Adagrad ,AdamW ,Adamax ,Ftrl ,Lion,LossScaleOptimizer ,Nadam ,RMSprop ,SGD \n",
    "import pandas as pd\n",
    "\n",
    "# Wczytanie danych z CSV\n",
    "data = pd.read_csv(\"harmonogram_data.csv\")\n",
    "\n",
    "# Podział na X (wejście: 5 kolumn) i Y (wyjście: 105 kolumn)\n",
    "X_cols = [f\"wanted_emp{i}\" for i in range(5)]\n",
    "Y_cols = [f\"out_{i}\" for i in range(105)]\n",
    "\n",
    "X = data[X_cols].values\n",
    "Y = data[Y_cols].values\n",
    "\n",
    "# Definicja modelu\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(5,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(105, activation='sigmoid'))  # 105 wyjść binarnych\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "\n",
    "# Trening\n",
    "model.fit(X, Y, epochs=50, batch_size=8, validation_split=0.2)\n",
    "\n",
    "# Po treningu możesz wypróbować prognozę:\n",
    "# (oczywiście sieć może \"głupoty\" przewidywać przy tak małej liczbie próbek)\n",
    "test_input = np.array([[3, 4, 5, 2, 5]])\n",
    "prediction = model.predict(test_input)\n",
    "print(\"Przewidywany harmonogram (pierwsze 21 wartości):\")\n",
    "print(prediction[0][:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0941e-d9f1-4970-87af-1afe38116b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
