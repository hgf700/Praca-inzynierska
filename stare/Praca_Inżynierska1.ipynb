{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f379d6-c675-446e-b649-72165bda0d83",
   "metadata": {},
   "source": [
    "# Creating randomized schedule data in a CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95e1dc1-2b8e-4d47-ac0c-f79f89fba470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV wygenerowano: data_csv\\grafik_30d_3s_24emp.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# --- PARAMETRY ---\n",
    "days = 30\n",
    "shifts = 3\n",
    "employees = 24 \n",
    "\n",
    "folder = \"data_csv\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "filename = os.path.join(folder, f\"grafik_{days}d_{shifts}s_{employees}emp.csv\")\n",
    "\n",
    "# --- GENEROWANIE CSV ---\n",
    "with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # --- 1. Nagłówki wymagań ---\n",
    "    req_headers = []\n",
    "    req_values = []\n",
    "\n",
    "    for day in range(1, days + 1):\n",
    "        for shift in range(1, shifts + 1):\n",
    "            req_headers.append(f\"req_{day}d_{shift}s\")\n",
    "            min_required = max(1, employees // 2)\n",
    "            max_required = employees - 1\n",
    "            req_values.append(random.randint(min_required, max_required))\n",
    "\n",
    "    writer.writerow(req_headers)\n",
    "    writer.writerow(req_values)\n",
    "\n",
    "    # --- 2. Nagłówki preferencji ---\n",
    "    pref_headers = [f\"pref_{day}d_{shift}s\" \n",
    "                    for day in range(1, days + 1) \n",
    "                    for shift in range(1, shifts + 1)]\n",
    "    writer.writerow(pref_headers)\n",
    "\n",
    "    # --- 3. Preferencje pracowników (każda linia = jeden pracownik) ---\n",
    "    for emp in range(1, employees + 1):\n",
    "        row = [random.randint(0, 1) for _ in pref_headers]\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"CSV wygenerowano:\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8904ab-827d-4ae7-bb71-4feb59ed9298",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# old csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1de57c-a2a8-4f05-af76-9372198ef3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "\n",
    "#  data is represented as example\n",
    "# 1,1,1,1,1,1,1,1,1,3,1,3,1,1,1,1,0,1,1,0,1\n",
    "# for 3 days and 3 employe\n",
    "# first part (1,1,1) stands for 1 day preferences of each employee\n",
    "# (3,1,3) stands for company requirments for each day\n",
    "# (1,0,1) last part for 3 day assigned is employe  1 and 3\n",
    "\n",
    "# Parametry\n",
    "days = 3\n",
    "employees = 3\n",
    "sample = 7\n",
    "max_tries = 1000\n",
    "name = f\"grafik_{sample}_{days}x{employees}.csv\"\n",
    "folder = \"data_csv\"\n",
    "FileName = os.path.join(folder, name)\n",
    "\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "def generate_preferences_for_employees(num_emps=employees, num_days=days):\n",
    "    return [[random.randint(0, 1) for _ in range(num_days)] for _ in range(num_emps)]\n",
    "\n",
    "def generate_schedule_from_preferences(preferences, firm_requirements, num_days=days):\n",
    "    num_emps = len(preferences)\n",
    "    schedule = [[0 for _ in range(num_emps)] for _ in range(num_days)]\n",
    "\n",
    "    for e in range(num_emps):\n",
    "        available_days = [d for d in range(num_days) if preferences[e][d] == 1]\n",
    "        if len(available_days) < firm_requirements[e]:\n",
    "            return None\n",
    "        chosen = random.sample(available_days, firm_requirements[e])\n",
    "        for d in chosen:\n",
    "            schedule[d][e] = 1\n",
    "\n",
    "    return schedule\n",
    "\n",
    "def is_schedule_valid(schedule, firm_requirements):\n",
    "    if schedule is None:\n",
    "        return False\n",
    "    num_days = len(schedule)\n",
    "    num_emps = len(schedule[0])\n",
    "    col_sums = [sum(schedule[d][e] for d in range(num_days)) for e in range(num_emps)]\n",
    "    return col_sums == firm_requirements\n",
    "\n",
    "def generate_dataset_csv(filename=FileName, num_samples=sample, num_emps=employees, num_days=days):\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        header = [\"sample\"]\n",
    "        for d in range(num_days):\n",
    "            for e in range(num_emps):\n",
    "                header.append(f\"emp{e}_pref{d}\")\n",
    "        header.extend([f\"req_worker{e}\" for e in range(num_emps)])\n",
    "        for d in range(num_days):\n",
    "            for e in range(num_emps):\n",
    "                header.append(f\"set_day{d}_emp{e}\")\n",
    "        header.append(\"mismatch_count\")\n",
    "        writer.writerow(header)\n",
    "\n",
    "        samples_generated = 0\n",
    "        attempts = 0\n",
    "\n",
    "        while samples_generated < num_samples and attempts < max_tries * num_samples:\n",
    "            preferences = generate_preferences_for_employees(num_emps, num_days)\n",
    "            firm_requirements = [random.randint(1, num_days) for _ in range(num_emps)]\n",
    "\n",
    "            if any(sum(preferences[e]) < firm_requirements[e] for e in range(num_emps)):\n",
    "                attempts += 1\n",
    "                continue\n",
    "\n",
    "            schedule = generate_schedule_from_preferences(preferences, firm_requirements, num_days)\n",
    "            if schedule is not None and is_schedule_valid(schedule, firm_requirements):\n",
    "                row = [samples_generated]\n",
    "\n",
    "                # Flatten preferences\n",
    "                flat_preferences = [preferences[e][d] for d in range(num_days) for e in range(num_emps)]\n",
    "                row.extend(flat_preferences)\n",
    "\n",
    "                row.extend(firm_requirements)\n",
    "\n",
    "                # Flatten schedule and calculate mismatch\n",
    "                flat_schedule = [schedule[d][e] for d in range(num_days) for e in range(num_emps)]\n",
    "                mismatch_count = sum(\n",
    "                    1 for pref, sched in zip(flat_preferences, flat_schedule) if pref != sched\n",
    "                )\n",
    "\n",
    "                row.extend(flat_schedule)\n",
    "                row.append(mismatch_count)\n",
    "\n",
    "                writer.writerow(row)\n",
    "                samples_generated += 1\n",
    "            attempts += 1\n",
    "\n",
    "        print(f\"Generated {samples_generated} samples after {attempts} attempts.\")\n",
    "        print(f\"File saved: {filename}\")\n",
    "\n",
    "generate_dataset_csv()\n",
    "\n",
    "def sum_mismatch_in_file(filename):\n",
    "    total_mismatch = 0\n",
    "    with open(filename, \"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "\n",
    "        mismatch_index = len(header) - 1  # ostatnia kolumna to mismatch_count\n",
    "\n",
    "        for row in reader:\n",
    "            total_mismatch += int(row[mismatch_index])\n",
    "\n",
    "    sum_val=sample/total_mismatch\n",
    "    print(f\"Sum of mismatch_count {total_mismatch}\")\n",
    "    print(f\"Mean value sample/total_mismatch {sum_val}\")\n",
    "    return None\n",
    "\n",
    "sum_mismatch_in_file(FileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846b4c0-7e95-46be-89d3-a04f14a55057",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41df8b0c-d1a9-4033-8d31-e635fcf72bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER098\\Documents\\GitHub\\Praca-inzynierska\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:640: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
      "```\n",
      "for metric in self.metrics:\n",
      "    metric.update_state(y, y_pred)\n",
      "```\n",
      "\n",
      "  return self._compiled_metrics_update_state(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Validation accuracy: 0.3000\n",
      "\n",
      "--- Fold 2/10 ---\n",
      "Fold 2 - Validation accuracy: 0.2000\n",
      "\n",
      "--- Fold 3/10 ---\n",
      "Fold 3 - Validation accuracy: 0.1000\n",
      "\n",
      "--- Fold 4/10 ---\n",
      "Fold 4 - Validation accuracy: 0.2000\n",
      "\n",
      "--- Fold 5/10 ---\n",
      "Fold 5 - Validation accuracy: 0.0000\n",
      "\n",
      "--- Fold 6/10 ---\n",
      "Fold 6 - Validation accuracy: 0.2000\n",
      "\n",
      "--- Fold 7/10 ---\n",
      "Fold 7 - Validation accuracy: 0.3000\n",
      "\n",
      "--- Fold 8/10 ---\n",
      "Fold 8 - Validation accuracy: 0.0000\n",
      "\n",
      "--- Fold 9/10 ---\n",
      "Fold 9 - Validation accuracy: 0.4000\n",
      "\n",
      "--- Fold 10/10 ---\n",
      "Fold 10 - Validation accuracy: 0.3000\n",
      "\n",
      "Średnia dokładność walidacji (accuracy): 0.2000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Binarna prognoza (0 = nie pracuje, 1 = pracuje):\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [1 0 0]]\n",
      "[[2. 3. 1.]]\n",
      "Predykcja ciągła (wartości zmiennoprzecinkowe):\n",
      "[[0.11137709 0.92319953 0.39152524]\n",
      " [0.9054446  0.97797245 0.6122471 ]\n",
      " [0.47718436 0.19971299 0.34023464]]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "\n",
    "\n",
    "filetoread=\"grafik_100_3x3.csv\"\n",
    "crossvalidationK=10\n",
    "\n",
    "\n",
    "data = pd.read_csv(filetoread)\n",
    "nameof_file_prediction=f\"predykcja_{filetoread}\"\n",
    "folder=\"data_csv\"\n",
    "resultofprediction =os.path.join(folder,nameof_file_prediction)\n",
    "\n",
    "X_cols = [\n",
    "    \"emp0_pref0day\", \"emp0_pref1day\", \"emp0_pref2day\",\n",
    "    \"emp1_pref0day\", \"emp1_pref1day\", \"emp1_pref2day\",\n",
    "    \"emp2_pref0day\", \"emp2_pref0day\", \"emp2_pref0day\",\n",
    "    \"req_worker0\", \"req_worker1\", \"req_worker2\"\n",
    "]\n",
    "\n",
    "Y_cols = [\n",
    "    \"set_day0_emp0\", \"set_day0_emp1\", \"set_day0_emp2\",\n",
    "    \"set_day1_emp0\", \"set_day1_emp1\", \"set_day1_emp2\",\n",
    "    \"set_day2_emp0\", \"set_day2_emp1\", \"set_day2_emp2\"\n",
    "]\n",
    "\n",
    "X = data[X_cols].values.astype(np.float32)\n",
    "Y = data[Y_cols].values.astype(np.float32)\n",
    "\n",
    "X_pref = X[:, :9]\n",
    "X_req = X[:, 9:]\n",
    "\n",
    "# Definicja niestandardowego modelu\n",
    "class CustomModel(Model):\n",
    "    def train_step(self, data):\n",
    "        (x, req_tensor), y_true = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self([x, req_tensor], training=True)\n",
    "\n",
    "            y_pred_reshaped = tf.reshape(y_pred, (-1, 3, 3))\n",
    "            assigned = tf.reduce_sum(y_pred_reshaped, axis=2)\n",
    "            penalty = tf.reduce_mean(tf.abs(assigned - req_tensor), axis=1)\n",
    "\n",
    "            bce = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "            total_loss = tf.reduce_mean(bce + 0.5 * penalty)\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Cross-walidacja K-Fold\n",
    "kf = KFold(n_splits=crossvalidationK, shuffle=True, random_state=42)\n",
    "val_accuracies = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{crossvalidationK} ---\")\n",
    "\n",
    "    X_pref_train, X_pref_val = X_pref[train_index], X_pref[test_index]\n",
    "    X_req_train, X_req_val = X_req[train_index], X_req[test_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[test_index]\n",
    "\n",
    "    input_main = Input(shape=(9,), name='preferences')\n",
    "    input_req = Input(shape=(3,), name='requirements')\n",
    "\n",
    "    x = Concatenate()([input_main, input_req])\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(9, activation='sigmoid')(x)\n",
    "\n",
    "    model = CustomModel(inputs=[input_main, input_req], outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0)\n",
    "\n",
    "    model.fit(\n",
    "        [X_pref_train, X_req_train],\n",
    "        Y_train,\n",
    "        validation_data=([X_pref_val, X_req_val], Y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = model.evaluate([X_pref_val, X_req_val], Y_val, verbose=0)\n",
    "    val_accuracies.append(val_acc)\n",
    "    print(f\"Fold {fold + 1} - Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nŚrednia dokładność walidacji (accuracy): {np.mean(val_accuracies):.4f}\")\n",
    "\n",
    "# Przykładowa prognoza\n",
    "test_pref = np.array([[0, 1, 1, 1, 1, 1, 0, 0, 1]]).astype(np.float32)  # Konwersja na float32\n",
    "test_req = np.array([[2, 3, 1]]).astype(np.float32)  # Konwersja na float32\n",
    "\n",
    "# Upewnij się, że przekazujesz dane wejściowe w postaci słownika\n",
    "prediction = model.predict({'preferences': test_pref, 'requirements': test_req})\n",
    "\n",
    "y_pred_binary = (prediction > 0.4).astype(int)\n",
    "\n",
    "print(\"Binarna prognoza (0 = nie pracuje, 1 = pracuje):\")\n",
    "print(y_pred_binary[0].reshape(3, 3))\n",
    "\n",
    "print(test_req)\n",
    "\n",
    "# Prognoza ciągła\n",
    "print(\"Predykcja ciągła (wartości zmiennoprzecinkowe):\")\n",
    "print(prediction[0].reshape(3, 3))\n",
    "\n",
    "# Predykcja na wszystkich 100 próbkach\n",
    "all_predictions = model.predict({'preferences': X_pref, 'requirements': X_req})\n",
    "all_predictions_binary = (all_predictions > 0.4).astype(int)\n",
    "\n",
    "columns = [\n",
    "    \"set_day0_emp0\", \"set_day0_emp1\", \"set_day0_emp2\",\n",
    "    \"set_day1_emp0\", \"set_day1_emp1\", \"set_day1_emp2\",\n",
    "    \"set_day2_emp0\", \"set_day2_emp1\", \"set_day2_emp2\"\n",
    "]\n",
    "\n",
    "df_cont = pd.DataFrame(all_predictions, columns=columns)\n",
    "df_cont.to_csv(resultofprediction, index_label=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52a1a3-ae55-44aa-9b4c-8431857a7084",
   "metadata": {},
   "source": [
    "# test of different optimizer and nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c0ed2-8cf7-4c46-bfe1-6e6b2e7ae728",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187e7a3-bfc4-479e-86ee-86d27c4bc12f",
   "metadata": {},
   "source": [
    "# not working yet larger nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5568d10e-0e0c-4d85-ae57-5148600ebf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarna prognoza (0 = nie pracuje, 1 = pracuje):\n",
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "[[3. 3. 3.]]\n",
      "Predykcja ciągła (wartości zmiennoprzecinkowe):\n",
      "[[0.54030275 0.60031474 0.49409747]\n",
      " [0.9185652  0.9128879  0.52074957]\n",
      " [0.39494663 0.39479718 0.20411442]]\n"
     ]
    }
   ],
   "source": [
    "test_pref = np.array([[0, 1, 1, 1, 1, 1, 0, 0, 1]]).astype(np.float32)  # Konwersja na float32\n",
    "test_req = np.array([[3, 3, 3]]).astype(np.float32)  # Konwersja na float32\n",
    "\n",
    "# Upewnij się, że przekazujesz dane wejściowe w postaci słownika\n",
    "y_pred_binary = (prediction > 0.4).astype(int)\n",
    "\n",
    "print(\"Binarna prognoza (0 = nie pracuje, 1 = pracuje):\")\n",
    "print(y_pred_binary[0].reshape(3, 3))\n",
    "\n",
    "print(test_req)\n",
    "\n",
    "# Prognoza ciągła\n",
    "print(\"Predykcja ciągła (wartości zmiennoprzecinkowe):\")\n",
    "print(prediction[0].reshape(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd90468-a263-4af5-8e49-4993e2ef23ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER098\\Documents\\GitHub\\Praca-inzynierska\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.1778 - loss: 0.6884 - val_accuracy: 0.2700 - val_loss: 0.6302\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2907 - loss: 0.6121 - val_accuracy: 0.2100 - val_loss: 0.5414\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2392 - loss: 0.5240 - val_accuracy: 0.2550 - val_loss: 0.4492\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2068 - loss: 0.4401 - val_accuracy: 0.2525 - val_loss: 0.3879\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2079 - loss: 0.3873 - val_accuracy: 0.2075 - val_loss: 0.3536\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2037 - loss: 0.3502 - val_accuracy: 0.1725 - val_loss: 0.3259\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2170 - loss: 0.3286 - val_accuracy: 0.2300 - val_loss: 0.3101\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1862 - loss: 0.3173 - val_accuracy: 0.2150 - val_loss: 0.3042\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2445 - loss: 0.3027 - val_accuracy: 0.2075 - val_loss: 0.3006\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2092 - loss: 0.3082 - val_accuracy: 0.1600 - val_loss: 0.2884\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2060 - loss: 0.2987 - val_accuracy: 0.2525 - val_loss: 0.2896\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2145 - loss: 0.2876 - val_accuracy: 0.2675 - val_loss: 0.2842\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2232 - loss: 0.2865 - val_accuracy: 0.1175 - val_loss: 0.2750\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2013 - loss: 0.2803 - val_accuracy: 0.3000 - val_loss: 0.2717\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2387 - loss: 0.2832 - val_accuracy: 0.2900 - val_loss: 0.2745\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2772 - loss: 0.2821 - val_accuracy: 0.1500 - val_loss: 0.2644\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1947 - loss: 0.2724 - val_accuracy: 0.2150 - val_loss: 0.2634\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2116 - loss: 0.2680 - val_accuracy: 0.3550 - val_loss: 0.2638\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2636 - loss: 0.2688 - val_accuracy: 0.1275 - val_loss: 0.2599\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1985 - loss: 0.2741 - val_accuracy: 0.2325 - val_loss: 0.2659\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1869 - loss: 0.2691 - val_accuracy: 0.3300 - val_loss: 0.2619\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2828 - loss: 0.2616 - val_accuracy: 0.2925 - val_loss: 0.2618\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2482 - loss: 0.2687 - val_accuracy: 0.3650 - val_loss: 0.2608\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2978 - loss: 0.2686 - val_accuracy: 0.0850 - val_loss: 0.2586\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2040 - loss: 0.2613 - val_accuracy: 0.1875 - val_loss: 0.2550\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2007 - loss: 0.2588 - val_accuracy: 0.2650 - val_loss: 0.2553\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2323 - loss: 0.2647 - val_accuracy: 0.2825 - val_loss: 0.2569\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2203 - loss: 0.2635 - val_accuracy: 0.2100 - val_loss: 0.2557\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2139 - loss: 0.2558 - val_accuracy: 0.2600 - val_loss: 0.2547\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2356 - loss: 0.2609 - val_accuracy: 0.3850 - val_loss: 0.2550\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2544 - loss: 0.2601 - val_accuracy: 0.2175 - val_loss: 0.2596\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2347 - loss: 0.2552 - val_accuracy: 0.1225 - val_loss: 0.2552\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2103 - loss: 0.2549 - val_accuracy: 0.2075 - val_loss: 0.2532\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2304 - loss: 0.2576 - val_accuracy: 0.2500 - val_loss: 0.2549\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2396 - loss: 0.2597 - val_accuracy: 0.2450 - val_loss: 0.2592\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2248 - loss: 0.2568 - val_accuracy: 0.2725 - val_loss: 0.2516\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1944 - loss: 0.2626 - val_accuracy: 0.2975 - val_loss: 0.2555\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2559 - loss: 0.2545 - val_accuracy: 0.1925 - val_loss: 0.2532\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1999 - loss: 0.2581 - val_accuracy: 0.1900 - val_loss: 0.2546\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2074 - loss: 0.2542 - val_accuracy: 0.2750 - val_loss: 0.2575\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2269 - loss: 0.2517 - val_accuracy: 0.0875 - val_loss: 0.2535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "Binarna prognoza (0 = nie pracuje, 1 = pracuje):\n",
      "[[0 1 0]\n",
      " [1 1 0]\n",
      " [1 1 1]]\n",
      "Przewidywany harmonogram (3 dni × 3 pracowników):\n",
      "[[0 1 1 1 1 1 0 0 1 2 3 1]]\n",
      "[[0.01007581 0.9554957  0.00368147]\n",
      " [0.9352067  0.9792307  0.01448628]\n",
      " [0.9658192  0.98265046 0.94451827]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Wczytanie danych z CSV\n",
    "data = pd.read_csv(\"grafik_2000_3x3.csv\")\n",
    "\n",
    "# Kolumny wejściowe (preferencje i wymagania)\n",
    "X_cols = [\n",
    "    \"emp0_pref0\", \"emp0_pref1\", \"emp0_pref2\",\n",
    "    \"emp1_pref0\", \"emp1_pref1\", \"emp1_pref2\",\n",
    "    \"emp2_pref0\", \"emp2_pref1\", \"emp2_pref2\",\n",
    "    \"req_worker0\", \"req_worker1\", \"req_worker2\"\n",
    "]\n",
    "\n",
    "Y_cols = [\n",
    "    \"day0_emp0\", \"day0_emp1\", \"day0_emp2\",\n",
    "    \"day1_emp0\", \"day1_emp1\", \"day1_emp2\",\n",
    "    \"day2_emp0\", \"day2_emp1\", \"day2_emp2\"\n",
    "]\n",
    "\n",
    "# Przygotowanie danych\n",
    "X = data[X_cols].values\n",
    "Y = data[Y_cols].values\n",
    "\n",
    "# Definicja modelu\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(12,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(9, activation='sigmoid'))  # 9 wyjść: 3 dni × 3 pracowników\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',     # możesz też użyć 'val_accuracy' itp.\n",
    "    patience=5,             # ile epok poczeka zanim zatrzyma\n",
    "    restore_best_weights=True # przywróć najlepszy model po zatrzymaniu\n",
    ")\n",
    "# Trening\n",
    "model.fit(X, Y, epochs=50, batch_size=32, callbacks=[early_stop] ,validation_split=0.2)\n",
    "\n",
    "# Przykładowa prognoza\n",
    "test_input = np.array([[0,1,1,1,1,1,0,0,1,2,3,1]])  # 12 wartości\n",
    "prediction = model.predict(test_input)\n",
    "y_pred_binary = (prediction > 0.5).astype(int)\n",
    "\n",
    "print(\"Binarna prognoza (0 = nie pracuje, 1 = pracuje):\")\n",
    "print(y_pred_binary[0].reshape(3, 3))\n",
    "\n",
    "print(\"Przewidywany harmonogram (3 dni × 3 pracowników):\")\n",
    "print(test_input)\n",
    "print(prediction[0].reshape(3, 3))\n",
    "# wiersz oznacza dzien kolumna przewidywania danego pracownika\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bade5b1-56e0-4f54-ac78-600ff4020aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER098\\Documents\\GitHub\\Praca-inzynierska\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.1268 - loss: 0.6504 - val_accuracy: 0.1900 - val_loss: 0.4997\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1981 - loss: 0.4504 - val_accuracy: 0.2300 - val_loss: 0.3642\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2003 - loss: 0.3511 - val_accuracy: 0.1225 - val_loss: 0.3353\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1684 - loss: 0.3162 - val_accuracy: 0.1675 - val_loss: 0.3148\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1711 - loss: 0.2999 - val_accuracy: 0.1850 - val_loss: 0.3076\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1927 - loss: 0.2889 - val_accuracy: 0.1575 - val_loss: 0.3124\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1819 - loss: 0.2880 - val_accuracy: 0.0700 - val_loss: 0.2944\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1881 - loss: 0.2833 - val_accuracy: 0.2750 - val_loss: 0.3062\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1657 - loss: 0.2773 - val_accuracy: 0.1050 - val_loss: 0.2950\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1658 - loss: 0.2753 - val_accuracy: 0.1400 - val_loss: 0.3085\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1855 - loss: 0.2719 - val_accuracy: 0.1875 - val_loss: 0.3032\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1835 - loss: 0.2648 - val_accuracy: 0.1725 - val_loss: 0.3041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "Przewidywany harmonogram (4 dni × 4 pracowników):\n",
      "[[1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 2 3 1 2]]\n",
      "[[5.9233493e-01 9.8475879e-01 7.2878180e-04 8.9546895e-01]\n",
      " [6.3681700e-03 9.9121469e-01 4.0709108e-01 6.6810779e-02]\n",
      " [7.9342073e-01 2.1962103e-01 3.5657844e-01 3.0866701e-02]\n",
      " [8.6838520e-01 2.5263199e-01 1.5198620e-01 9.6764213e-01]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Wczytanie danych z CSV\n",
    "data = pd.read_csv(\"grafik_2000_4x4.csv\")\n",
    "\n",
    "# Kolumny wejściowe (preferencje i wymagania)\n",
    "X_cols = [\n",
    "    \"emp0_pref0\", \"emp0_pref1\", \"emp0_pref2\", \"emp0_pref3\",\n",
    "    \"emp1_pref0\", \"emp1_pref1\", \"emp1_pref2\", \"emp1_pref3\",\n",
    "    \"emp2_pref0\", \"emp2_pref1\", \"emp2_pref2\", \"emp2_pref3\",\n",
    "    \"emp3_pref0\", \"emp3_pref1\", \"emp3_pref2\", \"emp3_pref3\",\n",
    "    \"req_worker0\", \"req_worker1\", \"req_worker2\", \"req_worker3\"\n",
    "]\n",
    "\n",
    "Y_cols = [\n",
    "    \"day0_emp0\", \"day0_emp1\", \"day0_emp2\", \"day0_emp3\",\n",
    "    \"day1_emp0\", \"day1_emp1\", \"day1_emp2\", \"day1_emp3\",\n",
    "    \"day2_emp0\", \"day2_emp1\", \"day2_emp2\", \"day2_emp3\",\n",
    "    \"day3_emp0\", \"day3_emp1\", \"day3_emp2\", \"day3_emp3\"\n",
    "]\n",
    "\n",
    "# Przygotowanie danych\n",
    "X = data[X_cols].values\n",
    "Y = data[Y_cols].values\n",
    "\n",
    "# Definicja modelu\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(20,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(16, activation='sigmoid'))\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trening modelu\n",
    "model.fit(X, Y, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Przykładowa prognoza\n",
    "# test_input: 16 preferencji (4 pracowników × 4 preferencje) + 4 wymagania\n",
    "test_input = np.array([[\n",
    "    1, 0, 1, 1,   # emp0\n",
    "    1, 1, 0, 0,   # emp1\n",
    "    0, 1, 1, 1,   # emp2\n",
    "    1, 0, 0, 1,   # emp3\n",
    "    2, 3, 1, 2    # wymagania na 4 dni\n",
    "]])\n",
    "\n",
    "prediction = model.predict(test_input)\n",
    "\n",
    "print(\"Przewidywany harmonogram (4 dni × 4 pracowników):\")\n",
    "print(test_input)\n",
    "print(prediction[0].reshape(4, 4))  # 4 dni × 4 pracowników\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41876c92-c9d7-4d72-8d15-ed7b7d08cbb3",
   "metadata": {},
   "source": [
    "# not working yet genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a5059f-0027-4c99-b698-b7208eaaea1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  225.84  272.95\n",
      "1  223.12  267.32\n",
      "2  222.40  261.88\n",
      "3  198.08  262.82\n",
      "4  198.08  263.29\n",
      "5  198.08  258.96\n",
      "6  198.08  257.52\n",
      "7  198.08  245.70\n",
      "8  198.08  239.17\n",
      "9  198.08  235.95\n",
      "10  198.08  239.81\n",
      "11  195.10  218.23\n",
      "12  191.89  211.16\n",
      "13  191.89  213.15\n",
      "14  191.89  237.59\n",
      "15  191.89  232.88\n",
      "16  188.58  217.79\n",
      "17  187.68  205.35\n",
      "18  186.88  226.44\n",
      "19  186.88  241.14\n",
      "20  186.88  236.91\n",
      "21  186.88  239.69\n",
      "22  182.84  218.72\n",
      "23  182.84  210.04\n",
      "24  182.84  223.81\n",
      "25  182.84  228.76\n",
      "26  182.84  235.37\n",
      "27  182.84  230.26\n",
      "28  181.14  219.61\n",
      "29  181.14  201.98\n",
      "30  181.14  194.75\n",
      "31  180.21  218.45\n",
      "32  180.21  224.19\n",
      "33  180.21  221.47\n",
      "34  180.21  231.32\n",
      "35  180.21  232.55\n",
      "36  180.21  224.21\n",
      "37  178.19  202.26\n",
      "38  178.19  199.23\n",
      "39  177.75  205.72\n",
      "40  177.75  210.04\n",
      "41  176.85  220.87\n",
      "42  176.85  217.38\n",
      "43  176.85  221.86\n",
      "44  176.85  197.97\n",
      "45  176.85  191.82\n",
      "46  175.05  184.08\n",
      "47  175.05  199.27\n",
      "48  175.05  204.93\n",
      "49  175.05  198.44\n",
      "50  175.05  197.55\n",
      "51  175.05  177.11\n",
      "52  175.05  177.57\n",
      "53  174.57  180.29\n",
      "54  174.57  177.65\n",
      "55  173.05  175.57\n",
      "56  173.05  189.40\n",
      "57  172.95  192.13\n",
      "58  172.95  208.66\n",
      "59  172.95  215.89\n",
      "60  172.12  219.51\n",
      "61  172.12  194.02\n",
      "62  172.12  185.41\n",
      "63  172.12  193.05\n",
      "64  172.12  174.39\n",
      "65  171.17  173.53\n",
      "66  171.17  178.13\n",
      "67  171.17  183.34\n",
      "68  171.17  184.03\n",
      "69  171.17  191.18\n",
      "70  171.17  191.80\n",
      "71  171.15  171.39\n",
      "72  171.15  192.14\n",
      "73  171.15  195.24\n",
      "74  170.90  198.96\n",
      "75  170.90  223.97\n",
      "76  170.90  219.61\n",
      "77  170.90  215.88\n",
      "78  170.90  232.57\n",
      "79  170.90  209.37\n",
      "80  170.07  193.08\n",
      "81  170.07  222.80\n",
      "82  170.07  225.03\n",
      "83  170.07  232.60\n",
      "84  170.07  223.33\n",
      "85  170.07  201.95\n",
      "86  169.89  172.36\n",
      "87  169.45  184.14\n",
      "88  169.40  194.90\n",
      "89  169.40  196.27\n",
      "90  169.40  217.07\n",
      "91  169.40  224.04\n",
      "92  168.38  205.50\n",
      "93  168.38  187.80\n",
      "94  168.38  195.42\n",
      "95  168.38  211.79\n",
      "96  168.38  208.59\n",
      "97  167.95  188.21\n",
      "98  167.83  190.46\n",
      "99  167.83  209.52\n",
      "100  167.83  237.40\n",
      "101  167.83  244.94\n",
      "102  167.83  235.04\n",
      "103  167.81  183.97\n",
      "104  167.78  185.14\n",
      "105  167.78  199.95\n",
      "106  167.78  222.33\n",
      "107  167.78  203.27\n",
      "108  167.78  207.92\n",
      "109  167.78  211.62\n",
      "110  167.78  174.81\n",
      "111  167.78  198.21\n",
      "112  167.78  201.79\n",
      "113  167.78  205.04\n",
      "114  167.78  221.76\n",
      "115  167.78  228.04\n",
      "116  167.78  224.72\n",
      "117  167.78  207.15\n",
      "118  167.35  201.28\n",
      "119  167.35  206.46\n",
      "120  167.35  208.44\n",
      "121  167.35  224.21\n",
      "122  167.32  210.05\n",
      "123  167.26  184.37\n",
      "124  167.26  183.44\n",
      "125  167.26  187.62\n",
      "126  166.91  185.98\n",
      "127  166.91  192.53\n",
      "128  166.91  205.84\n",
      "129  166.91  215.01\n",
      "130  166.91  182.06\n",
      "131  166.91  170.03\n",
      "132  166.91  167.32\n",
      "133  166.74  168.81\n",
      "134  166.74  170.58\n",
      "135  166.74  170.81\n",
      "136  166.74  172.10\n",
      "137  166.74  171.73\n",
      "138  166.74  171.52\n",
      "139  166.74  167.11\n",
      "140  166.74  170.55\n",
      "141  166.74  170.54\n",
      "142  166.74  167.85\n",
      "143  166.74  172.33\n",
      "144  166.74  170.17\n",
      "145  166.74  173.51\n",
      "146  166.74  167.91\n",
      "147  166.74  181.43\n",
      "148  166.65  190.38\n",
      "149  166.74  206.52\n",
      "150  166.74  180.47\n",
      "151  166.72  171.00\n",
      "152  166.72  181.29\n",
      "153  166.72  177.08\n",
      "154  166.74  181.88\n",
      "155  166.74  167.55\n",
      "156  166.72  167.81\n",
      "157  166.72  181.67\n",
      "158  166.72  179.85\n",
      "159  166.72  175.18\n",
      "160  166.72  186.85\n",
      "161  166.72  185.43\n",
      "162  166.72  189.04\n",
      "163  166.72  203.19\n",
      "164  166.70  169.52\n",
      "165  166.70  191.24\n",
      "166  166.70  188.45\n",
      "167  166.70  199.48\n",
      "168  166.70  203.39\n",
      "169  166.70  167.90\n",
      "170  166.70  167.16\n",
      "171  166.70  168.25\n",
      "172  166.70  171.06\n",
      "173  166.70  171.32\n",
      "174  166.70  169.03\n",
      "175  166.61  172.96\n",
      "176  166.61  181.65\n",
      "177  166.61  190.27\n",
      "178  166.61  188.02\n",
      "179  166.61  195.84\n",
      "180  166.61  195.30\n",
      "181  166.61  221.64\n",
      "182  166.61  226.19\n",
      "183  166.61  232.60\n",
      "184  166.61  230.54\n",
      "185  166.61  208.25\n",
      "186  166.61  196.86\n",
      "187  166.61  189.46\n",
      "188  166.61  195.36\n",
      "189  166.61  190.60\n",
      "190  166.61  210.39\n",
      "191  166.61  214.35\n",
      "192  166.61  219.05\n",
      "193  166.61  193.59\n",
      "194  166.61  167.64\n",
      "195  166.61  167.50\n",
      "196  166.61  167.04\n",
      "197  166.61  167.19\n",
      "198  166.61  167.01\n",
      "199  166.61  167.75\n",
      ", C L W ; / . D M Q\n",
      "H O A E F P N I T S\n",
      "X V G R Z B U Y K J\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class AG:\n",
    "    def __init__(self):\n",
    "        self.chromosome_length = 9\n",
    "        self.population_size = 100\n",
    "        self.number_of_epochs = 200\n",
    "        self.number_of_parents = 2\n",
    "        self.number_of_candidates = 8\n",
    "        self.mutation_probability = 0.1\n",
    "\n",
    "    def algorithm(self):\n",
    "        log_file = Path(f\"log-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.txt\")\n",
    "        string_builder = []\n",
    "\n",
    "        population = self.initialize_population(self.population_size)\n",
    "        children = self.initialize_population(self.population_size)\n",
    "\n",
    "        for epoch in range(self.number_of_epochs):\n",
    "            fitness = self.get_fitness(population)\n",
    "            population = [x for _, x in sorted(zip(fitness, population), key=lambda pair: pair[0])]\n",
    "            fitness.sort()\n",
    "\n",
    "            print(f\"{epoch}  {min(fitness):.2f}  {np.mean(fitness):.2f}\")\n",
    "            string_builder.append(f\"\\n{epoch}  {min(fitness):.2f}  {np.mean(fitness):.2f}\")\n",
    "\n",
    "            result = self.write_result(population[0])\n",
    "            if epoch == self.number_of_epochs - 1:\n",
    "                print(result)\n",
    "            string_builder.append(\"\\n\" + result + \"\\n\")\n",
    "\n",
    "            for p in range(int(0.1 * self.population_size), self.population_size):\n",
    "                parents, parent_ids = self.select_parents(fitness, population)\n",
    "                children[p] = self.generate_child_aex(parents)\n",
    "\n",
    "                for k in range(self.number_of_parents):\n",
    "                    string_builder.append(\" \".join(str(x) for x in parents[k]) + f\"   {fitness[parent_ids[k]]}\")\n",
    "                string_builder.append(\" \".join(str(x) for x in children[p]) + f\"   {self.get_fitness_single(children[p])}\\n\")\n",
    "\n",
    "            log_file.write_text(\"\\n\".join(string_builder), encoding='utf-8')\n",
    "\n",
    "            for p in range(int(0.1 * self.population_size), self.population_size):\n",
    "                population[p] = children[p][:]\n",
    "\n",
    "            for p in range(self.population_size):\n",
    "                if random.random() < self.mutation_probability:\n",
    "                    population[p] = self.mutation_swap(population[p])\n",
    "\n",
    "    def mutation_swap(self, pop):\n",
    "        x1 = random.randint(0, self.chromosome_length - 1)\n",
    "        x2 = random.randint(0, self.chromosome_length - 1)\n",
    "        pop[x1], pop[x2] = pop[x2], pop[x1]\n",
    "        return pop\n",
    "\n",
    "    def initialize_population(self, size):\n",
    "        base = list(range(ord('A'), ord('A') + 26)) + [91, 92, 93, 94]\n",
    "        return [random.sample(base, len(base)) for _ in range(size)]\n",
    "\n",
    "    def generate_child_aex(self, parents):\n",
    "        parent_length = len(parents[0])\n",
    "        current_vertex = parents[0][0]\n",
    "        child = [current_vertex]\n",
    "        available = set(parents[0])\n",
    "        available.remove(current_vertex)\n",
    "        counter = 1\n",
    "        parent_index = 0\n",
    "\n",
    "        while counter < parent_length:\n",
    "            next_vertex = -1\n",
    "            selected = parents[parent_index]\n",
    "            index = selected.index(current_vertex)\n",
    "            if index < parent_length - 1 and selected[index + 1] not in child:\n",
    "                next_vertex = selected[index + 1]\n",
    "                parent_index = (parent_index + 1) % len(parents)\n",
    "\n",
    "            if next_vertex == -1:\n",
    "                next_vertex = random.choice(list(available))\n",
    "            child.append(next_vertex)\n",
    "            available.remove(next_vertex)\n",
    "            current_vertex = next_vertex\n",
    "            counter += 1\n",
    "\n",
    "        return child\n",
    "\n",
    "    def get_fitness(self, population):\n",
    "        return [self.calculate_fitness(individual) for individual in population]\n",
    "\n",
    "    def get_fitness_single(self, individual):\n",
    "        return self.calculate_fitness(individual)\n",
    "\n",
    "    def calculate_fitness(self, chromosome):\n",
    "        fitness = 0\n",
    "        for i, gene in enumerate(chromosome):\n",
    "            if gene < ord('A'):\n",
    "                continue\n",
    "            fitness += self._frequency[gene - ord('A')] * self._weights[i]\n",
    "        return fitness\n",
    "\n",
    "    def select_parents(self, fitness, population):\n",
    "        selected_ids = []\n",
    "        for _ in range(self.number_of_parents):\n",
    "            candidates = random.sample(range(len(population)), self.number_of_candidates)\n",
    "            best = min(candidates, key=lambda i: fitness[i])\n",
    "            selected_ids.append(best)\n",
    "        return [population[i][:] for i in selected_ids], selected_ids\n",
    "\n",
    "    def write_result(self, chromosome):\n",
    "        result = []\n",
    "        for i in range(3):\n",
    "            row = []\n",
    "            for j in range(10):\n",
    "                val = chromosome[10 * i + j]\n",
    "                if val == 91:\n",
    "                    row.append(\".\")\n",
    "                elif val == 92:\n",
    "                    row.append(\",\")\n",
    "                elif val == 93:\n",
    "                    row.append(\";\")\n",
    "                elif val == 94:\n",
    "                    row.append(\"/\")\n",
    "                else:\n",
    "                    row.append(chr(val))\n",
    "            result.append(\" \".join(row))\n",
    "        return \"\\n\".join(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ag = AG()\n",
    "    ag.algorithm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffb3e4-8b34-4ace-a9ee-bd6877eca690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class GeneticScheduler:\n",
    "    def __init__(self, csv_path: str,\n",
    "                 population_size: int = 100,\n",
    "                 generations: int = 200,\n",
    "                 crossover_rate: float = 0.8,\n",
    "                 mutation_rate: float = 0.1,\n",
    "                 tournament_size: int = 3):\n",
    "        self.csv_path = csv_path\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.tournament_size = tournament_size\n",
    "\n",
    "        # Loaded from CSV\n",
    "        self.preferences = []     # flat list: emp0_day0, emp0_day1, ..., empN_dayM\n",
    "        self.requirements = []    # per day\n",
    "        self.num_employees = 0\n",
    "        self.num_days = 0\n",
    "        self.chromosome_length = 0\n",
    "\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Expects CSV with headers:\n",
    "        emp0_pref0, emp0_pref1, ..., empN_prefM,\n",
    "        req_worker0, ..., req_workerM,\n",
    "        day0_emp0, ..., dayM_empN\n",
    "        \"\"\"\n",
    "        with open(self.csv_path, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            data = next(reader)\n",
    "\n",
    "        # Determine dimensions from keys\n",
    "        pref_keys = [k for k in data.keys() if k.startswith('emp') and '_pref' in k]\n",
    "        req_keys = [k for k in data.keys() if k.startswith('req_worker')]\n",
    "        # sort keys to ensure order\n",
    "        pref_keys.sort(key=lambda x: (int(x.split('_pref')[0][3:]), int(x.split('_pref')[1])))\n",
    "        req_keys.sort(key=lambda x: int(x.replace('req_worker', '')))\n",
    "\n",
    "        # flatten preferences\n",
    "        self.preferences = [int(data[k]) for k in pref_keys]\n",
    "        self.requirements = [int(data[k]) for k in req_keys]\n",
    "\n",
    "        # infer dimensions\n",
    "        self.num_days = len(self.requirements)\n",
    "        self.num_employees = len(self.preferences) // self.num_days\n",
    "        self.chromosome_length = self.num_days * self.num_employees\n",
    "\n",
    "    def _initialize_population(self):\n",
    "        # each gene: 0 (off) or 1 (on)\n",
    "        return [ [random.randint(0,1) for _ in range(self.chromosome_length)]\n",
    "                 for _ in range(self.population_size) ]\n",
    "\n",
    "    def _fitness(self, chromosome: list) -> float:\n",
    "        score = 0\n",
    "        # Preference score: match preferred assignment\n",
    "        for emp in range(self.num_employees):\n",
    "            for day in range(self.num_days):\n",
    "                gene = chromosome[day*self.num_employees + emp]\n",
    "                pref = self.preferences[emp*self.num_days + day]\n",
    "                # if matches preference (1=works,0=off)\n",
    "                if gene == pref:\n",
    "                    score += 1\n",
    "        # Requirement penalty\n",
    "        for day in range(self.num_days):\n",
    "            assigned = sum(chromosome[day*self.num_employees + emp]\n",
    "                           for emp in range(self.num_employees))\n",
    "            required = self.requirements[day]\n",
    "            # penalty for shortage or surplus\n",
    "            if assigned < required:\n",
    "                score -= 10 * (required - assigned)\n",
    "            elif assigned > required:\n",
    "                score -= 5 * (assigned - required)\n",
    "        return score\n",
    "\n",
    "    def _select_parent(self, population, fitnesses):\n",
    "        # tournament selection\n",
    "        candidates = random.sample(list(enumerate(population)), self.tournament_size)\n",
    "        # select best fitness\n",
    "        best = max(candidates, key=lambda x: fitnesses[x[0]])\n",
    "        return best[1]\n",
    "\n",
    "    def _crossover(self, parent1: list, parent2: list) -> list:\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy()\n",
    "        point = random.randint(1, self.chromosome_length - 1)\n",
    "        child = parent1[:point] + parent2[point:]\n",
    "        return child\n",
    "\n",
    "    def _mutate(self, chromosome: list):\n",
    "        for i in range(self.chromosome_length):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                chromosome[i] = 1 - chromosome[i]\n",
    "        return chromosome\n",
    "\n",
    "    def run(self):\n",
    "        population = self._initialize_population()\n",
    "        best_solution = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        for gen in range(self.generations):\n",
    "            fitnesses = [self._fitness(ch) for ch in population]\n",
    "            # track best\n",
    "            idx = int(np.argmax(fitnesses))\n",
    "            if fitnesses[idx] > best_score:\n",
    "                best_score = fitnesses[idx]\n",
    "                best_solution = population[idx].copy()\n",
    "\n",
    "            # report\n",
    "            avg_fit = sum(fitnesses) / len(fitnesses)\n",
    "            print(f\"Gen {gen:3d}: best={best_score:.2f}, avg={avg_fit:.2f}\")\n",
    "\n",
    "            # new population\n",
    "            new_pop = []\n",
    "            while len(new_pop) < self.population_size:\n",
    "                p1 = self._select_parent(population, fitnesses)\n",
    "                p2 = self._select_parent(population, fitnesses)\n",
    "                child = self._crossover(p1, p2)\n",
    "                child = self._mutate(child)\n",
    "                new_pop.append(child)\n",
    "            population = new_pop\n",
    "\n",
    "        print(\"\\nBest schedule fitness:\", best_score)\n",
    "        print(self.format_solution(best_solution))\n",
    "        return best_solution, best_score\n",
    "\n",
    "    def format_solution(self, chromosome: list) -> str:\n",
    "        # Pretty-print grid of days × employees\n",
    "        lines = []\n",
    "        for day in range(self.num_days):\n",
    "            row = chromosome[day*self.num_employees:(day+1)*self.num_employees]\n",
    "            lines.append(' '.join(str(x) for x in row))\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Genetic Scheduler for work plan optimization\")\n",
    "    parser.add_argument('csvfile', help=\"Input CSV file with preferences and requirements\")\n",
    "    parser.add_argument('-p', '--population', type=int, default=100)\n",
    "    parser.add_argument('-g', '--generations', type=int, default=200)\n",
    "    parser.add_argument('-c', '--crossover', type=float, default=0.8)\n",
    "    parser.add_argument('-m', '--mutation', type=float, default=0.1)\n",
    "    parser.add_argument('-t', '--tournament', type=int, default=3)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    scheduler = GeneticScheduler(\n",
    "        csv_path=args.csvfile,\n",
    "        population_size=args.population,\n",
    "        generations=args.generations,\n",
    "        crossover_rate=args.crossover,\n",
    "        mutation_rate=args.mutation,\n",
    "        tournament_size=args.tournament\n",
    "    )\n",
    "    scheduler.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
